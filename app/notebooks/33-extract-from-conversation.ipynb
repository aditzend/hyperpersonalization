{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "class AtlasClient ():\n",
    "\n",
    "\n",
    "   def __init__ (self, altas_uri, dbname):\n",
    "       self.mongodb_client = MongoClient(altas_uri)\n",
    "       self.database = self.mongodb_client[dbname]\n",
    "\n",
    "\n",
    "   ## A quick way to test if we can connect to Atlas instance\n",
    "   def ping (self):\n",
    "       self.mongodb_client.admin.command('ping')\n",
    "\n",
    "\n",
    "   def get_collection (self, collection_name):\n",
    "       collection = self.database[collection_name]\n",
    "       return collection\n",
    "\n",
    "\n",
    "   def find (self, collection_name, filter = {}, limit=10):\n",
    "       collection = self.database[collection_name]\n",
    "       items = list(collection.find(filter=filter, limit=limit))\n",
    "       return items\n",
    "\n",
    "\n",
    "   # https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/\n",
    "   def vector_search(self, collection_name, index_name, attr_name, embedding_vector, limit=5):\n",
    "       collection = self.database[collection_name]\n",
    "       results = collection.aggregate([\n",
    "           {\n",
    "               '$vectorSearch': {\n",
    "                   \"index\": index_name,\n",
    "                   \"path\": attr_name,\n",
    "                   \"queryVector\": embedding_vector,\n",
    "                   \"numCandidates\": 50,\n",
    "                   \"limit\": limit,\n",
    "               }\n",
    "           },\n",
    "           ## We are extracting 'vectorSearchScore' here\n",
    "           ## columns with 1 are included, columns with 0 are excluded\n",
    "           {\n",
    "               \"$project\": {\n",
    "                   '_id' : 1,\n",
    "                   'title' : 1,\n",
    "                   'plot' : 1,\n",
    "                   'year' : 1,\n",
    "                   \"search_score\": { \"$meta\": \"vectorSearchScore\" }\n",
    "           }\n",
    "           }\n",
    "           ])\n",
    "       return list(results)\n",
    "\n",
    "\n",
    "   def close_connection(self):\n",
    "       self.mongodb_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Atlas instance! We are good to go!\n"
     ]
    }
   ],
   "source": [
    "mongo_uri = os.getenv(\"MONGODB_URI\")\n",
    "atlas_client = AtlasClient (mongo_uri, 'hyper')\n",
    "atlas_client.ping()\n",
    "print ('Connected to Atlas instance! We are good to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database: hyper\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to local MongoDB Atlas\n",
    "mongo_uri = os.getenv(\"MONGODB_URI\")\n",
    "if not mongo_uri:\n",
    "    raise ValueError(\"MONGODB_URI environment variable is not set\")\n",
    "\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client.get_database(\"hyper\")\n",
    "\n",
    "print(f\"Connected to database: {db.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "norman_collection = db[\"Norman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_system_user(\n",
    "    system_message: str, user_message: str, model: str = \"gpt-3.5-turbo\"\n",
    "):\n",
    "    \"\"\"Para usar en notebooks\"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={ \"type\": \"json_object\" }\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"OpenAI API request failed: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_contexts =  [\n",
    "        {\n",
    "          \"messages\": [\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Soy Alexander, mi madre se llama Sylvia, te paso los datos de ella mail: sylvia@gmail.com celu 1123343434.\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Excelente Alexander, como puedo ayudarte?\"  \n",
    "              },\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"quiero sacar un turno para ella porque no entiende nada de tecnologia y los turnos se sacan por esta via\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"No hay problema, sacamos el turno para ella, cual es el DNI de ella?\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"12668992\"\n",
    "              },\n",
    "              {\n",
    "                  \"role\": \"assistant\",\n",
    "                  \"content\": \"perfecto, digame que especialidad?\"  \n",
    "              },\n",
    "              {\n",
    "                  \"role\": \"user\",\n",
    "                  \"content\": \"ginecologia\"\n",
    "              },\n",
    "              {\n",
    "                  \"role\": \"assistant\",\n",
    "                  \"content\": \"Tengo turnos disponibles con el Dr. Facundo Farias para el 27 de agosto a las 10:00hs, le parece bien?\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"si\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"confirmado entonces el turno para Sylvia para el 27 de agosto a las 10:00hs con el Dr. Facundo Farias. Le envio el comprobante por mail?\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"si\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Al correo de Sylvia?\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"si\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Perfecto, le envio el comprobante al mail de ella. Algo mas que pueda ayudarte?\"\n",
    "              },\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"no, muchas gracias\"\n",
    "              }\n",
    "           ],\n",
    "          \"metadata\": {\n",
    "            \"session_id\": \"1\",\n",
    "            \"person_id\": \"20\",\n",
    "            \"context_id\": \"1\",\n",
    "            \"created_at\": \"20200825T12:00:00.000Z\",\n",
    "          },\n",
    "        },     \n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"given_name\": \"Alexander\",\n",
      "  \"relationship_to_master_node\": \"self\",\n",
      "  \"mother\": {\n",
      "    \"given_name\": \"Sylvia\",\n",
      "    \"email\": \"sylvia@gmail.com\",\n",
      "    \"phone\": \"1123343434\",\n",
      "    \"DNI\": \"12668992\",\n",
      "    \"appointment\": {\n",
      "      \"specialty\": \"ginecologia\",\n",
      "      \"doctor\": \"Dr. Facundo Farias\",\n",
      "      \"date\": \"2020-08-27\",\n",
      "      \"time\": \"10:00\"\n",
      "    }\n",
      "  },\n",
      "  \"data_gathered_at\": \"2020-08-25T12:00:00.000Z\"\n",
      "} \n",
      "\n",
      "\n",
      "///////////////////////////\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for context in condensed_contexts:\n",
    "        # Join all messages in one string by a comma\n",
    "        messages = ''.join([str(message) for message in context['messages']])\n",
    "        # print(messages)\n",
    "        # print(context['metadata'])\n",
    "        extraction = gpt_system_user(\n",
    "            system_message=\"\"\"\n",
    "              Extract every meaningful information about Alexander Ditzend from the provided conversation.\n",
    "              Ask yourself, what happened in the conversation?\n",
    "              What data about the user did you learn?\n",
    "              At what date and time was this data gathered?\n",
    "\n",
    "\n",
    "              Use this JSON example as a format, the master_node is Alexander Ditzend:\n",
    "             \n",
    "              {\n",
    "                given_name: \"Julia\",\n",
    "                family_name:\"Hernandez\",\n",
    "                age:18,\n",
    "                relationship_to_master_node:\"sons_girlfriend\"\n",
    "                ...other metadata you consider relevant\n",
    "              }\n",
    "\n",
    "              \"\"\",\n",
    "            user_message=f\" METADATA: ```{context['metadata']} CONVERSATION: ```{messages}``` ```\",\n",
    "            model=\"gpt-4o-2024-08-06\"\n",
    "        )\n",
    "        if extraction == None:\n",
    "            print(f\"Error: Openai API returned status error\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"{extraction} \\n\\n\\n///////////////////////////\\n\\n\\n\")\n",
    "            # Convert the extraction string to a dictionary\n",
    "            extraction_dict = json.loads(extraction)\n",
    "            \n",
    "            # Insert the dictionary into the collection\n",
    "            norman_collection.insert_one(extraction_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema es que está toda la data mezclada. Así quedaría en el mismo vector. Pruebo pidiendo que devuelva una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"records\": [\n",
      "    {\n",
      "      \"record_type\": \"personal_info\",\n",
      "      \"given_name\": \"Sylvia\",\n",
      "      \"relationship_to_master_node\": \"mother\",\n",
      "      \"relationship_from_master_node\": \"son\",\n",
      "      \"email\": \"sylvia@gmail.com\",\n",
      "      \"phone\": \"1123343434\",\n",
      "      \"DNI\": \"12668992\",\n",
      "      \"datetime\": \"2020-08-25T12:00:00.000Z\"\n",
      "    },\n",
      "    {\n",
      "      \"record_type\": \"appointment\",\n",
      "      \"for\": \"Sylvia\",\n",
      "      \"specialty\": \"ginecologia\",\n",
      "      \"doctor\": \"Dr. Facundo Farias\",\n",
      "      \"appointment_date\": \"2020-08-27\",\n",
      "      \"appointment_time\": \"10:00\",\n",
      "      \"datetime\": \"2020-08-25T12:00:00.000Z\"\n",
      "    }\n",
      "  ]\n",
      "} \n",
      "\n",
      "\n",
      "///////////////////////////\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for context in condensed_contexts:\n",
    "        # Join all messages in one string by a comma\n",
    "        messages = ''.join([str(message) for message in context['messages']])\n",
    "        # print(messages)\n",
    "        # print(context['metadata'])\n",
    "        extraction = gpt_system_user(\n",
    "            system_message=\"\"\"\n",
    "              Extract every meaningful information about Alexander Ditzend from the provided conversation.\n",
    "              Ask yourself, what happened in the conversation?\n",
    "              What data about the user did you learn?\n",
    "              At what date and time was this data gathered?\n",
    "              Each piece of information should be an item in a list.\n",
    "            Datetime is the moment the memory was created, use always ISO 8601 format.\n",
    "        \n",
    "\n",
    "              Use this JSON example as a format, the master_node is Alexander Ditzend:\n",
    "             {\n",
    "                \"records\": [\n",
    "                {\n",
    "                    \"record_type\": \"personal_info\",\n",
    "                    \"given_name\": \"Sylvia\",\n",
    "                    \"relationship_to_master_node\": \"mother\",\n",
    "                    \"relationship_from_master_node\": \"son\",\n",
    "                    \"email\": \"sylvia@gmail.com\",\n",
    "                    \"phone\": \"1123343434\",\n",
    "                    \"DNI\": \"12668992\",\n",
    "                    \"datetime\": \"2020-08-25T12:00:00.000Z\",\n",
    "                    },\n",
    "                   {\n",
    "                    \"record_type\": \"appointment\",\n",
    "                    \"for\": \"Sylvia\",\n",
    "                    \"specialty\": \"ginecologia\",\n",
    "                    \"doctor\": \"Dr. Facundo Farias\",\n",
    "                    \"appointment_date\": \"2020-08-27\",\n",
    "                    \"appointment_time\": \"10:00\",\n",
    "                    \"datetime\": \"2020-08-27T10:00:00.000Z\"\n",
    "                    },\n",
    "                    ...other records\n",
    "                ]\n",
    "              }\n",
    "              \"\"\",\n",
    "            user_message=f\" METADATA: ```{context['metadata']} CONVERSATION: ```{messages}``` ```\",\n",
    "            model=\"gpt-4o-2024-08-06\"\n",
    "        )\n",
    "        if extraction == None:\n",
    "            print(f\"Error: Openai API returned status error\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"{extraction} \\n\\n\\n///////////////////////////\\n\\n\\n\")\n",
    "            # Convert the extraction string to a dictionary\n",
    "            extraction_dict = json.loads(extraction)\n",
    "            \n",
    "            # Insert the list of dictionaries into the collection\n",
    "            norman_collection.insert_many(extraction_dict['records'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezclando data y fechas de dos contextos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " On August 25, at 12:00 PM the user provided the following information about themselves and their related person:\n",
      "- User's name: Alexander\n",
      "- User's related person: Sylvia (mother)\n",
      "- Sylvia's email: sylvia@gmail.com\n",
      "- Sylvia's phone number: 1123343434\n",
      "- Sylvia's DNI (identification number): 12668992\n",
      "\n",
      "Additionally, the user requested assistance in scheduling a medical appointment for Sylvia in the field of gynecology. The assistant provided available time slots for the appointment and confirmed a specific date and time with the user (August 27, at 10:00 AM with Dr. Facundo Farias). The user confirmed the appointment and requested that the appointment confirmation be sent to Sylvia's email.\n",
      "\n",
      "In conclusion, the user's name is Alexander and they requested assistance in scheduling a gynecology appointment for their mother, Sylvia. The appointment was successfully scheduled for August 27, at 10:00 AM with Dr. Facundo Farias, and the appointment confirmation will be sent to Sylvia's email. {'session_id': '1', 'person_id': '20', 'context_id': '1', 'created_at': '20200825T12:00:00.000Z'}\n",
      "---------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = \"yo tengo algun turno asignado?\"\n",
    "filter = {\"person_id\": \"20\"}\n",
    "db_results = db.similarity_search_with_score(query=user_input, embeddings=embeddings, filter=filter, k=2)\n",
    "context_k2 = [f'\\n {db_results[i][0].page_content} {db_results[i][0].metadata}\\n---------------\\n\\n' for i in range(len(db_results))]\n",
    "context = context_k2\n",
    "for c in context:\n",
    "    print(c)\n",
    "system_prompt = f\"\"\"\n",
    "You are the personal assistant of the user.\n",
    "Use the user's name in your answers.\n",
    "Direct your answers to the user in the second person.\n",
    "You will find past conversations between you and the user between backticks.\n",
    "Use them to answer the user's question.\n",
    "To reason about dates, have in mind that today is September 13th, 2023.\n",
    "Wait before answering, check when the data was gathered first.\n",
    "Take a deep breath and work on this problem step-by-step.\n",
    "\n",
    "\n",
    "\n",
    "```{context}```\n",
    "\n",
    "\"\"\"\n",
    "# answer = gpt_system_user(system_message=system_prompt, user_message=user_input, model=\"gpt-4\")\n",
    "answer = gpt_system_user(system_message=system_prompt, user_message=user_input)\n",
    "# answer[\"text\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hasta donde sé, el último turno que asignamos fue para Sylvia, tu madre, el 27 de agosto a las 10:00 AM con el Dr. Facundo Farias. Sin embargo, esta información fue proporcionada el 25 de agosto. Permíteme verificar si ha habido alguna actualización desde entonces. Por favor, dame un momento.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[\"text\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca hay un error de razonamiento pero es mucho pedir para un prompt tan corto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posibles pasos siguientes:\n",
    "\n",
    "- Navegar el grafo de relaciones del usuario y cambiar el punto focal actual. \"este turno es para mi madre\"\n",
    "- Usar el mismo metodo para guardar cosas como \"La madre del usuario tiene un turno para el dentista el 1 de enero de 2021\"\n",
    "- Sumar muchos mas datos personales y ver si hay confusiones\n",
    "- Simular llamados a APIs desde diferentes relaciones del usuario y ver si hay confusiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexander/Projects/hyperpersonalization/app/notebooks/14.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexander/Projects/hyperpersonalization/app/notebooks/14.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m user_input \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mque edad tenia yo en 1988?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexander/Projects/hyperpersonalization/app/notebooks/14.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfilter\u001b[39m \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mperson_id\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m20\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexander/Projects/hyperpersonalization/app/notebooks/14.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m db_results \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39msimilarity_search_with_score(query\u001b[39m=\u001b[39muser_input, embeddings\u001b[39m=\u001b[39membeddings, \u001b[39mfilter\u001b[39m\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m, k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexander/Projects/hyperpersonalization/app/notebooks/14.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m context_k2 \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mdb_results[i][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mpage_content\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mdb_results[i][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmetadata\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m---------------\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(db_results))]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexander/Projects/hyperpersonalization/app/notebooks/14.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m context \u001b[39m=\u001b[39m context_k2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "user_input = \"que edad tenia yo en 1988?\"\n",
    "filter = {\"person_id\": \"20\"}\n",
    "db_results = db.similarity_search_with_score(query=user_input, embeddings=embeddings, filter=filter, k=2)\n",
    "context_k2 = [f'\\n {db_results[i][0].page_content} {db_results[i][0].metadata}\\n---------------\\n\\n' for i in range(len(db_results))]\n",
    "context = context_k2\n",
    "for c in context:\n",
    "    print(c)\n",
    "system_prompt = f\"\"\"\n",
    "You are the best personal assistant of SAIA Air.\n",
    "Your job is to help users in their travel needs.\n",
    "Use the user's name in your answers.\n",
    "You will find past conversations between you and the user between backticks.\n",
    "Use them to answer the user's question.\n",
    "To reason about dates, have in mind that today is September 13th, 2023.\n",
    "Wait before answering, check when the data was gathered first.\n",
    "Take a deep breath and work on this problem step-by-step.\n",
    "\n",
    "\n",
    "\n",
    "```{context}```\n",
    "\n",
    "\"\"\"\n",
    "answer = gpt_system_user(system_message=system_prompt, user_message=user_input, model=\"gpt-4\")\n",
    "answer[\"text\"][\"content\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
